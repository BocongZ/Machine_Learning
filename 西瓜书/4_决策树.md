*流程*
1.终止条件 
所有节点属于同一类;属性集为空;样本集为空
2.叶子节点是样本

*划分条件 3种*
1.信息增益
父节点的信息熵 - 子节点的信息熵(子节点按照数量分配weight)
2.信息增益率P75
避免信息增益对于数据集数量大的偏好。所以我们往往从划分属性信息增益高于平均值的属性中选择信息增益率最大的作为划分属性
3.基尼系数
Gini_index 1-sum(pk)^2

*剪枝处理*
1.pre-pruning
validation验证新的划分降低精度,则不再划分(缺点: 舍弃后续划分可能提高精度的情况)
2.post-pruning
通过生成fully-grown tree再剪枝,将所有的剪枝后的tree进行一遍对比(缺点:耗时)
优点: 比前剪枝保留更多的分支

*连续值和缺失值*
1.连续值
寻找最大的增益的划分点,作为连续值的划分
e.g. 密度和糖分
2.缺失值
寻找相似划分的特征替代 ; 或者将缺失划分属性点样本点加入所有子分支,对其乘以子分支占据父节点样本的数量的比率

*多变量决策树*
划分属性的线性组合  ==> 原始decision stump画平行坐标轴的直线,线性组合后可以画斜线
e.g. 西瓜密度和糖分的线性组合作为一个新的划分属性
