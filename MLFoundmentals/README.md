# Lecture Directory  
   
*When can Machines Learn?*   
> 1.机器学习问题   
> 2.二分类   
> 3.不同的ML类型   
> 4.可行性    
> hw0: 条件概率 and 贝叶斯公式    
> hw1: Perceptron and Pocket algorithm实现      
            
*Why can Machines Learn?*     
> 1.growthFunction,breakPoint   
> 2.ML泛化理论   
> 3.VC维度,边界   
> 4.噪声和错误估计   
> hw2:错误率 VC bound计算样本数目N   
    
*How can Machines Learn?*   
> 1.线性回归,伪逆矩阵,squaredError  
> 2.逻辑回归,sidmod函数,crossEntropyError  
> 3.多分类问题,SGD  
> 4.非线性问题的featureTransform  
> hw3:损失函数,linear/logistic(SGD) algorithm实现   
       
*How can Machines Learn Better?*      
> 1.过度拟合的危害,避免的方法   
> 2.有约束的regularizer   
> 3.验证集validation作用     
> 4.小技巧,课程总结       
>hw4:添加项regularization,验证集valiadation的实现,计算     
     
